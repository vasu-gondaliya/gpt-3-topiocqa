# Modelling GPT-3 for Open Domain Conversational Question Answering with Topic Switching
In a general knowledge-seeking environment, people pose questions related to a specific topic that they seek to acquire information about. As the conversation progresses, the questions asked are based on the answers to the previous questions. Oftentimes, it is the case that such conversations cultivate an emerging interest in the questioner about the topic which might result in a  different yet somewhat related topic being asked in a particular conversation. Most of the currently trained models are trained upon publicly available datasets that either include conversations that are closed domain, resulting in the scope of the topics being limited due to the availability of reference texts or conversations that do not employ topic-switching in a single conversation. We present a sophisticated Natural Language  Processing (NLP) model built upon auto-regressive GPT-3 that explores open-domain conversations and utilizes the Wikipedia-based TopiOCQA dataset to generate free-form conversational answers to questions being asked, preserving topic-switching between conversations. The TopiOCQA dataset contains about 4-5 topics in a single conversation with 3920 conversations in the whole dataset and an average of 10-12 questions asked per conversation. As opposed to ubiquitous conversations that incorporate extractive text spans, our project employs free-form conversations and is capable of providing answers to questions without leveraging any reference information that provides the questioner with the ability to ask questions kindred to preceding responses.
